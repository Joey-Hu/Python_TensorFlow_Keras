{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ../../data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ../../data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ../../data/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "Iter0,Testing Acc 0.8316\n",
      "Iter1,Testing Acc 0.871\n",
      "Iter2,Testing Acc 0.882\n",
      "Iter3,Testing Acc 0.8872\n",
      "Iter4,Testing Acc 0.8936\n",
      "Iter5,Testing Acc 0.8966\n",
      "Iter6,Testing Acc 0.8993\n",
      "Iter7,Testing Acc 0.9022\n",
      "Iter8,Testing Acc 0.9036\n",
      "Iter9,Testing Acc 0.9052\n",
      "Iter10,Testing Acc 0.9058\n",
      "Iter11,Testing Acc 0.9068\n",
      "Iter12,Testing Acc 0.908\n",
      "Iter13,Testing Acc 0.9092\n",
      "Iter14,Testing Acc 0.9096\n",
      "Iter15,Testing Acc 0.9109\n",
      "Iter16,Testing Acc 0.9118\n",
      "Iter17,Testing Acc 0.9121\n",
      "Iter18,Testing Acc 0.9128\n",
      "Iter19,Testing Acc 0.9138\n",
      "Iter20,Testing Acc 0.9135\n"
     ]
    }
   ],
   "source": [
    "# 载入数据集\n",
    "mnist = input_data.read_data_sets(\"../../data/mnist\", one_hot=True)\n",
    "\n",
    "# 定义每个批次大小(50?, 200?)\n",
    "batch_size = 100\n",
    "\n",
    "# 计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "# 定义两个placeholder\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# 创建一个简单的神经网络(增加隐藏层?)\n",
    "Weights = tf.Variable(tf.zeros([784, 10]))    # 给一个非0的初始值?\n",
    "biases = tf.Variable(tf.zeros([10]))    # 给一个非0的初始值?\n",
    "prediction = tf.nn.softmax(tf.matmul(x, Weights) + biases)    # 使用sigmoid? ReLU?\n",
    "\n",
    "# 二次代价函数(交叉熵?)\n",
    "loss = tf.reduce_mean(tf.square(y - prediction))\n",
    "\n",
    "# 梯度下降法最小化代价函数（使用其他优化方式?）\n",
    "train = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "# 初始化变量 \n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 存放结果在一个布尔型列表中\n",
    "# 首先让我们找出那些预测正确的标签。tf.argmax 是一个非常有用的函数，\n",
    "# 它能给出某个tensor对象在某一维上的其数据最大值所在的索引值。由于标签向量是由0,1组成，因此最大值1所在的索引位置就是类别标签，\n",
    "# 比如tf.argmax(y,1)返回的是模型对于任一输入x预测到的标签值，而 tf.argmax(y_,1) 代表正确的标签，\n",
    "# 我们可以用 tf.equal 来检测我们的预测是否真实标签匹配(索引位置一样表示匹配)。\n",
    "correct_prediction = tf.equal(tf.arg_max(y,1), tf.arg_max(prediction,1))\n",
    "\n",
    "# 求准确率\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# 执行会话\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(21):    # 训练更多次数?\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train, feed_dict={x: batch_xs, y: batch_ys})\n",
    "        acc = sess.run(accuracy, feed_dict={x: mnist.test.images, y: mnist.test.labels})\n",
    "        print(\"Iter\" + str(epoch) + \",Testing Acc \" + str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "修改上面可修改的变量，是ACC提升到95%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
